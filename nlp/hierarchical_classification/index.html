<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="层次文本分类论文（Hierarchical Text Classification）"><meta name="keywords" content="NLP"><meta name="author" content="lalalei"><meta name="copyright" content="lalalei"><meta name="theme-color" content="#0078E7"><title>层次文本分类论文（Hierarchical Text Classification） | 啦啦蕾的日常</title><link rel="shortcut icon" href="/images/favicon.png"><link rel="mask-icon" href="/images/favicon.png" color="#0078E7"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script id="yun-config">
    let Yun = window.Yun || {};
    let CONFIG = {"root":"/","title":"啦啦蕾的日常","version":"0.6.0","anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><script src="//at.alicdn.com/t/font_1140697_n3htx7s57pp.js" async></script><meta name="generator" content="Hexo 4.2.0"><link rel="stylesheet" href="/css/prism.css" type="text/css"></head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle sidebar-toggle-fixed hty-icon-button"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><aside class="sidebar"><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc sidebar-nav-active hty-icon-button" data-target="post-toc-wrap" title="Table of Contents"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="Overview"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about" title="lalalei"><img loading="lazy" src="/images/avatar.jpeg" alt="lalalei"></a><div class="site-author-name"><a href="/about/">lalalei</a></div><a class="site-name" href="/about/site.html">啦啦蕾的日常</a><sub class="site-subtitle"></sub><div class="site-desciption">认清这个世界，并爱她～</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="Home"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item site-state-posts"><a href="/archives" title="Archives"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">14</span></a></div><div class="site-state-item site-state-categories"><a href="/categories" title="Categories"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">8</span></a></div><div class="site-state-item site-state-tags"><a href="/tags" title="Tags"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">9</span></a></div><a class="site-state-item hty-icon-button" href="https://yun.yunyoujun.cn" title="文档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-settings-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/lalalei21" title="GitHub" target="_blank" style="color:#181717"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:15623600813@163.com" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="我的小伙伴们" style="color:dodgerblue"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-genderless-line"></use></svg></a></div></div><script defer src="/js/sidebar.js"></script><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#存在问题"><span class="toc-number">1.</span> <span class="toc-text">存在问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#论文集锦"><span class="toc-number">2.</span> <span class="toc-text">论文集锦</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#专利分类毕业论文"><span class="toc-number">3.</span> <span class="toc-text">专利分类毕业论文</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Weakly-Supervised-Hierarchical-Text-Classification"><span class="toc-number">3.1.</span> <span class="toc-text">Weakly-Supervised Hierarchical Text Classification</span></a></li></ol></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="post-block" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/nlp/hierarchical_classification/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="lalalei"><meta itemprop="description" content="层次文本分类论文（Hierarchical Text Classification）"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="啦啦蕾的日常"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">层次文本分类论文（Hierarchical Text Classification）</h1><div class="post-meta"><div class="post-time" style="display:inline-block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="Created: 2019-11-12 14:52:26" itemprop="dateCreated datePublished" datetime="2019-11-12T14:52:26+08:00">2019-11-12</time><span class="post-meta-divider">-</span><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-2-line"></use></svg></span> <time title="Modified: 2020-04-21 20:34:46" itemprop="dateModified" datetime="2020-04-21T20:34:46+08:00">2020-04-21</time></div><div class="post-classify"><span class="post-category"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a class="category" href="/categories/%E5%95%A6%E5%95%A6%E8%95%BE%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BD%9E/" itemprop="url" rel="index"><span itemprop="text">啦啦蕾的学习笔记～</span></a></span> > <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a class="category" href="/categories/%E5%95%A6%E5%95%A6%E8%95%BE%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BD%9E/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/" itemprop="url" rel="index"><span itemprop="text">论文分享</span></a></span> > <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a class="category" href="/categories/%E5%95%A6%E5%95%A6%E8%95%BE%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BD%9E/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/" itemprop="url" rel="index"><span itemprop="text">文本分类</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag" href="/tags/NLP/"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">NLP</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content post-markdown"><p><strong>层次文本分类</strong>是一种特殊的文本分类任务。它的分类标签具有树状层次结构。</p>
<h3 id="存在问题"><a href="#存在问题" class="headerlink" title="存在问题"></a>存在问题</h3><ul>
<li>使用分类标签结构信息。</li>
<li>类别规模过大。</li>
<li>类别对应的训练样本数目不足且不平衡。<a id="more"></a>                                    

</li>
</ul>
<h3 id="论文集锦"><a href="#论文集锦" class="headerlink" title="论文集锦"></a>论文集锦</h3><table>
<thead>
<tr>
<th>序号</th>
<th>论文标题</th>
<th>发表机构</th>
<th>简单描述</th>
<th>代码</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>00</td>
<td><strong>A Survey of Hierarchical Classification</strong></td>
<td>2011</td>
<td>层次分类综述。flat、local（分三种）、big bang (global)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>01</td>
<td>Hierarchical Text Classification and Evaluation</td>
<td>IEEE 2001</td>
<td>定义了多级分类两种评价指标。基于类别相似度和相似距离。</td>
<td></td>
<td></td>
</tr>
<tr>
<td>02</td>
<td>Label Embedding Trees for Large Multi-Class Tasks</td>
<td>NIPS 2010 Bengio</td>
<td>没看明白。。。</td>
<td></td>
<td></td>
</tr>
<tr>
<td>03</td>
<td>Hierarchical multi-label classification using local neural networks</td>
<td>计算机与系统科学学报 2014</td>
<td></td>
<td></td>
<td><a href="https://www.sciencedirect.com/science/article/pii/S0022000013000718">链接</a></td>
</tr>
<tr>
<td>1</td>
<td>Hierarchical Deep Convolutional Neural Network for Large Scale Visual Recognition</td>
<td>IEEE 2015</td>
<td>视觉识别任务，<strong>HDCNNs</strong>，将embedding deep CNNs引入到分类层次结构中</td>
<td></td>
<td></td>
</tr>
<tr>
<td>2</td>
<td><strong>Initializing neural networks for hierarchical multi-label text classification</strong></td>
<td>BioNLP 2017</td>
<td>用训练数据中的标签共现来初始化最后的隐层参数。</td>
<td></td>
<td></td>
</tr>
<tr>
<td>3</td>
<td><strong>HDLTex: Hierarchical Deep Learning for Text Classification</strong></td>
<td>ICMLA 2017</td>
<td>二级分类，一级训练完划分文档，二级再训练</td>
<td><a href="https://github.com/kk7nc/HDLTex">Keras</a></td>
<td></td>
</tr>
<tr>
<td>4</td>
<td><strong>Hierarchical Multi-Label Classification Networks</strong></td>
<td>ICML 2018</td>
<td><strong>HMCN</strong>。HMCN-F前馈、HMCN-R循环，融合全局和局部处理方式</td>
<td></td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>Large-Scale Hierarchical Text Classification with Recursively Regularized Deep Graph-CNN</td>
<td>WWW 2018</td>
<td><strong>DGCNN</strong>。Recursive Regularization loss function</td>
<td></td>
<td></td>
</tr>
<tr>
<td>6</td>
<td>An Analysis of Hierarchical Text Classification Using Word Embeddings</td>
<td>Information Sciences 2018</td>
<td>使用词嵌入（GloVe, word2vec, and fastText）+机器学习分类算法（fastText, XGBoost, SVM, and Keras’ CNN）</td>
<td></td>
<td></td>
</tr>
<tr>
<td>7</td>
<td><strong>A Hierarchical Neural Attention-based Text Classifier</strong></td>
<td>EMNLP 2018</td>
<td>encoder：bilstm编码word，decoder：每一级的label与隐层编码结果进行attention。</td>
<td><a href="https://github.com/koustuvsinha/hier-class">Pytorch</a></td>
<td><a href="https://github.com/fatecbf/toutiao-multilevel-text-classfication-dataset/">层次分类数据集</a><br>后续要看的参考文献3篇</td>
</tr>
<tr>
<td>8</td>
<td><strong>Learning Hierarchical Category Structure for Multi-label Short Text Categorization</strong></td>
<td>EMNLP 2018</td>
<td><strong>HFT-CNN</strong>。Hierarchical Fine-tune CNN。<strong>短文本分类</strong>，类似<strong>迁移学习</strong>，基于每个父节点的local classification，父节点嵌入层和卷积层参数共享给子节点。打分机制：BSF和MSF。</td>
<td><a href="https://github.com/ShimShim46/HFT-CNN">Chainer</a></td>
<td></td>
</tr>
<tr>
<td>9</td>
<td><a href="#Weakly-Supervised-Hierarchical-Text-Classification">Weakly-Supervised Hierarchical Text Classification</a></td>
<td>AAAI 2019</td>
<td><strong>WeSHClass</strong>。1.提供少量类相关词或文档，使用语言模型生成伪数据。2.利用伪数据构建预训练局部分类器。3.融合所有局部分类器，生成全局分类器，在真实数据上迭代自训练。4.阻塞机制，防止强制性叶子节点预测。</td>
<td><a href="https://github.com/yumeng5/WeSHClass">GitHub</a></td>
<td></td>
</tr>
<tr>
<td>10</td>
<td><strong>Hierarchical Text Classification with Reinforced Label Assignment</strong></td>
<td>EMNLP 2019</td>
<td><strong>HiLAP</strong>。<strong>将层次分类视为一个马尔可夫决策过程</strong>，学习一个Label <strong>Assignment</strong> Policy决定当前实例放在哪个标签上，啥时候停止。</td>
<td><a href="https://github.com/morningmoni/HiLAP">GitHub</a></td>
<td></td>
</tr>
<tr>
<td>11</td>
<td><strong>NeuralClassifier: An Open-source Neural Hierarchical Multi-label Text Classification Toolkit</strong></td>
<td>ACL 2019</td>
<td>腾讯的开源工具，pytorch，为了快速建立层次多标签分类神经网络模型。提供多种文本编码器，如fasttext、textcnn、textrnn等。</td>
<td><a href="https://github.com/Tencent/NeuralNLP-NeuralClassifier">GitHub</a></td>
<td>后续要了解的：region embbedding</td>
</tr>
<tr>
<td>12</td>
<td><strong>Hierarchical Multi-label Classification of Text with Capsule Networks</strong></td>
<td>ACL 2019</td>
<td>使用最简单的<strong>胶囊网络</strong>来进行层次分类。分类不一致策略。利用标签初始化权重。</td>
<td><a href="https://github.com/uhh-lt/BlurbGenreCollection-HMC">GitHub</a></td>
<td></td>
</tr>
<tr>
<td>13</td>
<td><strong>Hierarchical Transfer Learning for Multi-label Text Classification</strong></td>
<td>ACL 2019</td>
<td><strong>HTrans</strong>。利用<strong>迁移学习</strong>。给每个类别训练二分类器，父的参数给子类用，输出层训练，用高学习率；其他层参数保持，用低学习率；冻结嵌入层。训练优化类别权重。</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>A structured self-attentive sentence embedding </p>
<p>Generative and discriminative text classification with recurrent neural networks </p>
<h3 id="专利分类毕业论文"><a href="#专利分类毕业论文" class="headerlink" title="专利分类毕业论文"></a>专利分类毕业论文</h3><p>参考链接：<a href="http://kns.cnki.net/kns/brief/Default_Result.aspx">知网</a>、</p>
<table>
<thead>
<tr>
<th>论文标题</th>
<th>作者</th>
<th>时间</th>
<th>来源</th>
<th>简单描述</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>基于深度学习的专利文本分析方法研究</td>
<td>王英瑜</td>
<td>2019</td>
<td>北京邮电大学</td>
<td>topic model + cnn/rcnn</td>
<td></td>
</tr>
<tr>
<td>中文专利的自动分类</td>
<td>牛世雄</td>
<td>2017</td>
<td>大连理工</td>
<td>tf-idf特征提取，词向量+空间向量/词袋模型的文本表示，重点在于提出了新的文本表示方法</td>
<td></td>
</tr>
<tr>
<td>基于深度学习理论与方法的中文专利文本自动分类研究</td>
<td>马双刚</td>
<td>2016</td>
<td>江苏大学</td>
<td>分词+DAE自动编码器特征提取+SVM分类器</td>
<td></td>
</tr>
</tbody></table>
<p>&nbsp;</p>
<h4 id="Weakly-Supervised-Hierarchical-Text-Classification"><a href="#Weakly-Supervised-Hierarchical-Text-Classification" class="headerlink" title="Weakly-Supervised Hierarchical Text Classification"></a>Weakly-Supervised Hierarchical Text Classification</h4><ul>
<li><p>摘要</p>
<p>层次文本分类目的是将文本分类到给定层次中，这是实际任务。存在问题：1. 依赖大量训练数据 2. 不容易确定合适的分类级别（非强制性叶子节点预测）。</p>
<p>本文提出一种弱监督神经网络方法。1. 它不需要大量训练数据，只需要几个弱监督信号，如与类相关的文档或关键字。2. 以此生成伪数据进行局部模型预训练，3. 再对真实未标注数据自训练，迭代的精化模型。4. 最后通过阻塞机制确定文档的合适级别。</p>
</li>
<li><p>方法</p>
<p>用户提供少量与叶子类相关的信号（词或文档），父类是叶子类的聚合。</p>
<p>Class category tree: $T$    Text Collection: $D=\lbrace D_1,D_2,…,D_N\rbrace$</p>
<p>Word-level supervision: $S$     Document-level supervision: $D^L$</p>
<ul>
<li><p><strong>Pseudo Document Generation 伪数据生成</strong>：</p>
<ul>
<li><p><strong>Modeling Class Distribution 建模类分布</strong>：<br>将每个类建模为高维球形概率分布。训练<code>Skip-Gram</code>模型学习词向量，对所有词嵌入标准化，映射在一个单位球上。<strong>对于每个类 $C_j \in T$，语义建模为movMF分布的混合（这一步不是很理解，公式太复杂）。</strong><br><strong>关键字集合检索</strong>：1. 提供词，在词向量空间中找到最接近这几个词平均向量的几个关键字；2. 提供文档，使用<code>TF-IDF</code>权值从$D^L_j$中提取代表性关键字。<br>优点：与直接使用弱监督信号相比，此方法具有平滑效果，降低了模型对弱监督信号的敏感度。</p>
</li>
<li><p><strong>Language Model Based Document Generation</strong>：使用<code>LSTM</code>语言模型生成伪数据。生成$C_j$的伪文档：从$C_j$的movMF分布中抽取一个向量，选择向量空间中最接近的词作为序列的起始词。<br>优点：1. 由于初始词直接来自类分布，可以保证生成的文档与$C_j$相关。2. 通过混合分布建模，$C_j$ 的每个子类的语义信息都有机会被包含在伪文档中，从而使训练后的神经模型具有更好的泛化能力。</p>
</li>
</ul>
</li>
<li><p><strong>Local Classifier Pre-Training</strong>：<br>使用<strong>伪数据</strong>，为每个父类构建<strong>预训练局部分类模型</strong>$M_p$。为了避免对伪数据过拟合，在真实数据上表现不好，使用<strong>伪标签$l^*_{ij}$</strong>来代替<code>one-hot</code>编码，使用超参数$\alpha$表示伪数据中的<strong>噪声</strong>。<br>$$<br>l^<em>_{ij} = \begin{cases}<br>(1-\alpha)+\alpha/m,\quad D^</em>_i\ is\ generated\ from\ class\ j\</p>
<pre><code>\alpha/m,\quad otherwise</code></pre><p>  \end{cases}<br>$$<br>$m$是相对应的子类数目，使用<code><a href="https://www.jianshu.com/p/43318a3dc715">KL divergence</a> loss</code>作为预测值$Y$到$L^<em>$的损失函数。<br>$$<br>loss = KL(L^</em>||Y)=\sum_i\sum_jl^<em>_{ij}log\frac{l^</em><em>{ij}}{y</em>{ij}}<br>$$</p>
</li>
<li><p>Global Classifier Self-Training**：</p>
<p>对每一层都需要输出所有类的概率分布。从根开始融合局部分类器，使用条件概率公式累乘，构建全局分类器$G_k$。</p>
<p>优点：<strong>Greedy top-down</strong>方法会有错误传播，且错误无法更正。通过累乘给了低级别纠正高级别错误的机会。</p>
<p>在<strong>未标记真实数据</strong>，使用$G_k$进行预测并迭代精调。模型输出$y_{ij}$，$f_j$是<strong>soft frequency</strong>，设置的伪标签$L^{<strong>}$，最小化<code><a href="https://www.jianshu.com/p/43318a3dc715">KL divergence</a> loss</code>：<br>$$<br>l^{</strong>}<em>{ij}=\frac{y^2</em>{ij}/f_j}{\sum_{y’}y^2_{ij’}/f_{j’}},\ f_j=\sum_iy_{ij}<br>$$<br>当语料库中少于$\delta$的文档类分配更改时停止迭代。</p>
</li>
<li><p><strong>Blocking Mechanism</strong>：</p>
<p>为了强制性叶子节点预测，使用<strong>阻塞机制</strong>。当被分类到中间节点$C_j$时，使用其局部分类器的输出$q$，判断此刻是否需阻塞，即它若与<code>one-hot</code>接近则表示它应分配给相应子类，若与一致分布接近则停止。</p>
<p>用<code>normalized entropy</code>作为阻塞度量，$m$是子类数$\geq2$，$0\leq\gamma\leq1$，$\gamma=1$表示无阻塞全被分到叶子。此度量one-hot时为0，均匀分布时为1。<br>$$<br>-\ \frac{1}{log\ m}\sum_{i=1}^{m}q_i\ log\ q_i &gt; \gamma<br>$$</p>
</li>
</ul>
</li>
<li><p>实验</p>
<p>在<a href="http://developer.nytimes.com/">The New York Times(NYT)</a> - 5/25、<a href="https://arxiv.org/">arXiv</a> - 3/53、Yelp Review - 3/5 三个数据上实验。</p>
<p>基线：Hier-Dataless、Hier-SVM、CNN、WeSTClass、<strong>No-global</strong>、<strong>No-vMF</strong>、<strong>No-selftrain</strong>。</p>
</li>
<li><p>想法</p>
<p>本文构造伪数据的方法值得借鉴学习。</p>
<p>但是存在一个问题，此文是基于给定的数据集上生成伪数据进行训练，若是新增一批同源测试集，模型需要重新训练吗，若不那么模型是否能在新数据集上表现良好。</p>
</li>
</ul>
</div><div id="reward-container"><span class="hty-icon-button button-glow" id="reward-button" title="Donate" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === &quot;none&quot;) ? &quot;block&quot; : &quot;none&quot;;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span><div id="reward-comment">我很可爱，请给我钱</div><div id="qr" style="display:none;"><div style="display:inline-block"><a href="/images/alipay.jpg"><img loading="lazy" src="/images/alipay.jpg" alt="支付宝" title="支付宝"></a><div><span style="color:#00A3EE"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-alipay-line"></use></svg></span></div></div><div style="display:inline-block"><a href="/images/weixin.jpg"><img loading="lazy" src="/images/weixin.jpg" alt="微信支付" title="微信支付"></a><div><span style="color:#2DC100"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-pay-line"></use></svg></span></div></div></div></div><ul class="post-copyright"><li class="post-copyright-author"><strong>Post author: </strong>lalalei</li><li class="post-copyright-link"><strong>Post link: </strong><a href="http://yoursite.com/nlp/hierarchical_classification/" title="层次文本分类论文（Hierarchical Text Classification）">http://yoursite.com/nlp/hierarchical_classification/</a></li><li class="post-copyright-license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> unless stating additionally.</li></ul></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/nlp/NER/" rel="prev" title="领域适应NER论文"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">领域适应NER论文</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/nlp/text_classification/" rel="next" title="Text Classification 文本分类论文"><span class="post-nav-text">Text Classification 文本分类论文</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div><div id="comment"><div class="comment-tooltip text-center"><span>若您无 GitHub 账号，可直接在下方匿名评论。</span><br><span>若您想及时得到回复提醒，建议跳转 GitHub Issues 评论。</span><br><span>若没有本文 Issue，您可以使用 Comment 模版新建。</span><br><a class="hty-button hty-button--raised" id="github-issues" href="https://github.com/YunYouJun/yunyoujun.github.io/issues?q=is:issue+层次文本分类论文（Hierarchical Text Classification）">GitHub Issues</a></div></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2020 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> lalalei</span></div><div class="powered"><span>Powered by <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> v4.2.0</span><span class="footer-separator">|</span><span>Theme - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v0.6.0</span></div><div class="live_time"><span>本博客已萌萌哒地运行</span><span id="display_live_time"></span><span class="moe-text">(●'◡'●)</span><script>function blog_live_time() {
  window.setTimeout(blog_live_time, 1000);
  const start = new Date('2019-08-08T00:00:00');
  const now = new Date();
  const timeDiff = (now.getTime() - start.getTime());
  const msPerMinute = 60 * 1000;
  const msPerHour = 60 * msPerMinute;
  const msPerDay = 24 * msPerHour;
  const passDay = Math.floor(timeDiff / msPerDay);
  const passHour = Math.floor((timeDiff % msPerDay) / 60 / 60 / 1000);
  const passMinute = Math.floor((timeDiff % msPerHour) / 60 / 1000);
  const passSecond = Math.floor((timeDiff % msPerMinute) / 1000);
  display_live_time.innerHTML = " " + passDay + " 天 " + passHour + " 小时 " + passMinute + " 分 " + passSecond + " 秒";
}
blog_live_time();
</script></div></footer><a class="hty-icon-button" id="goUp" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a></div><script defer src="/js/utils.js"></script><script defer src="/js/hexo-theme-yun.js"></script></body></html>